{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c20aa28",
   "metadata": {},
   "source": [
    "## ChromaDB 만들고 답변 가지고 오기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f60370",
   "metadata": {},
   "source": [
    "---\n",
    "### Chromadb\n",
    "- embedding model : 'all-MiniLM-L6-v2'\n",
    "- Document(page_content = 태그 , metadata = 나머지 정보들)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d2ce399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromadb\n",
      "  Downloading chromadb-1.1.0-cp39-abi3-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Downloading build-1.3.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\brain\\anaconda3\\envs\\llm_env\\lib\\site-packages (from chromadb) (2.11.7)\n",
      "Collecting pybase64>=1.4.1 (from chromadb)\n",
      "  Downloading pybase64-1.4.2-cp312-cp312-win_amd64.whl.metadata (9.0 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvicorn-0.37.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: numpy>=1.22.5 in c:\\users\\brain\\anaconda3\\envs\\llm_env\\lib\\site-packages (from chromadb) (2.3.2)\n",
      "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
      "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\brain\\anaconda3\\envs\\llm_env\\lib\\site-packages (from chromadb) (4.15.0)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Downloading onnxruntime-1.22.1-cp312-cp312-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_api-1.37.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_sdk-1.37.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\brain\\anaconda3\\envs\\llm_env\\lib\\site-packages (from chromadb) (0.22.0)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\brain\\anaconda3\\envs\\llm_env\\lib\\site-packages (from chromadb) (4.67.1)\n",
      "Collecting overrides>=7.3.1 (from chromadb)\n",
      "  Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting importlib-resources (from chromadb)\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromadb)\n",
      "  Downloading grpcio-1.75.0-cp312-cp312-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Downloading bcrypt-4.3.0-cp39-abi3-win_amd64.whl.metadata (10 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb)\n",
      "  Downloading typer-0.19.2-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\brain\\anaconda3\\envs\\llm_env\\lib\\site-packages (from chromadb) (9.1.2)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in c:\\users\\brain\\anaconda3\\envs\\llm_env\\lib\\site-packages (from chromadb) (6.0.2)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Downloading mmh3-5.2.0-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\brain\\anaconda3\\envs\\llm_env\\lib\\site-packages (from chromadb) (3.11.3)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\brain\\anaconda3\\envs\\llm_env\\lib\\site-packages (from chromadb) (0.28.1)\n",
      "Collecting rich>=10.11.0 (from chromadb)\n",
      "  Using cached rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in c:\\users\\brain\\anaconda3\\envs\\llm_env\\lib\\site-packages (from chromadb) (4.25.1)\n",
      "Requirement already satisfied: requests<3.0,>=2.7 in c:\\users\\brain\\anaconda3\\envs\\llm_env\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.32.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\brain\\anaconda3\\envs\\llm_env\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in c:\\users\\brain\\anaconda3\\envs\\llm_env\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.9.0.post0)\n",
      "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: distro>=1.5.0 in c:\\users\\brain\\anaconda3\\envs\\llm_env\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\brain\\anaconda3\\envs\\llm_env\\lib\\site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\brain\\anaconda3\\envs\\llm_env\\lib\\site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\brain\\anaconda3\\envs\\llm_env\\lib\\site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\brain\\anaconda3\\envs\\llm_env\\lib\\site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (2025.8.3)\n",
      "Requirement already satisfied: packaging>=19.1 in c:\\users\\brain\\anaconda3\\envs\\llm_env\\lib\\site-packages (from build>=1.0.3->chromadb) (25.0)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\brain\\anaconda3\\envs\\llm_env\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: anyio in c:\\users\\brain\\anaconda3\\envs\\llm_env\\lib\\site-packages (from httpx>=0.27.0->chromadb) (4.10.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\brain\\anaconda3\\envs\\llm_env\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\brain\\anaconda3\\envs\\llm_env\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\brain\\anaconda3\\envs\\llm_env\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\brain\\anaconda3\\envs\\llm_env\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\brain\\anaconda3\\envs\\llm_env\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\brain\\anaconda3\\envs\\llm_env\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.27.1)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading google_auth-2.40.3-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\brain\\anaconda3\\envs\\llm_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading protobuf-6.32.1-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: sympy in c:\\users\\brain\\anaconda3\\envs\\llm_env\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Collecting importlib-metadata<8.8.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting zipp>=3.20 (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting googleapis-common-protos~=1.57 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.37.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.37.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_proto-1.37.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.58b0 (from opentelemetry-sdk>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_semantic_conventions-0.58b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\brain\\anaconda3\\envs\\llm_env\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\brain\\anaconda3\\envs\\llm_env\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\brain\\anaconda3\\envs\\llm_env\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.4.1)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->chromadb)\n",
      "  Using cached markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\brain\\anaconda3\\envs\\llm_env\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\brain\\anaconda3\\envs\\llm_env\\lib\\site-packages (from tokenizers>=0.13.2->chromadb) (0.34.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\brain\\anaconda3\\envs\\llm_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\brain\\anaconda3\\envs\\llm_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.7.0)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\brain\\anaconda3\\envs\\llm_env\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading httptools-0.6.4-cp312-cp312-win_amd64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\brain\\anaconda3\\envs\\llm_env\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading watchfiles-1.1.0-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached websockets-15.0.1-cp312-cp312-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\brain\\anaconda3\\envs\\llm_env\\lib\\site-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\brain\\anaconda3\\envs\\llm_env\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Downloading chromadb-1.1.0-cp39-abi3-win_amd64.whl (19.8 MB)\n",
      "   ---------------------------------------- 0.0/19.8 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.3/19.8 MB 6.7 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 4.5/19.8 MB 11.2 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 6.8/19.8 MB 11.3 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 12.1/19.8 MB 14.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 16.0/19.8 MB 15.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  19.7/19.8 MB 16.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 19.8/19.8 MB 15.2 MB/s eta 0:00:00\n",
      "Downloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading bcrypt-4.3.0-cp39-abi3-win_amd64.whl (152 kB)\n",
      "Downloading build-1.3.0-py3-none-any.whl (23 kB)\n",
      "Downloading grpcio-1.75.0-cp312-cp312-win_amd64.whl (4.6 MB)\n",
      "   ---------------------------------------- 0.0/4.6 MB ? eta -:--:--\n",
      "   ------------------------------- -------- 3.7/4.6 MB 18.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.6/4.6 MB 17.5 MB/s eta 0:00:00\n",
      "Downloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.9/1.9 MB 21.5 MB/s eta 0:00:00\n",
      "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Downloading google_auth-2.40.3-py2.py3-none-any.whl (216 kB)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading mmh3-5.2.0-cp312-cp312-win_amd64.whl (41 kB)\n",
      "Downloading oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
      "Downloading onnxruntime-1.22.1-cp312-cp312-win_amd64.whl (12.7 MB)\n",
      "   ---------------------------------------- 0.0/12.7 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 5.2/12.7 MB 24.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.3/12.7 MB 27.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.7/12.7 MB 23.4 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_api-1.37.0-py3-none-any.whl (65 kB)\n",
      "Downloading importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl (19 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.37.0-py3-none-any.whl (72 kB)\n",
      "Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Downloading opentelemetry_sdk-1.37.0-py3-none-any.whl (131 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.58b0-py3-none-any.whl (207 kB)\n",
      "Downloading protobuf-6.32.1-cp310-abi3-win_amd64.whl (435 kB)\n",
      "Using cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Downloading pybase64-1.4.2-cp312-cp312-win_amd64.whl (35 kB)\n",
      "Using cached rich-14.1.0-py3-none-any.whl (243 kB)\n",
      "Using cached markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading typer-0.19.2-py3-none-any.whl (46 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading uvicorn-0.37.0-py3-none-any.whl (67 kB)\n",
      "Downloading httptools-0.6.4-cp312-cp312-win_amd64.whl (88 kB)\n",
      "Downloading watchfiles-1.1.0-cp312-cp312-win_amd64.whl (292 kB)\n",
      "Using cached websockets-15.0.1-cp312-cp312-win_amd64.whl (176 kB)\n",
      "Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Downloading pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml): started\n",
      "  Building wheel for pypika (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53916 sha256=2a56483dd8edaf042f07743878a50f608ebf8119fd21b96584e29797cf448be1\n",
      "  Stored in directory: c:\\users\\brain\\appdata\\local\\pip\\cache\\wheels\\d5\\3d\\69\\8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, flatbuffers, durationpy, zipp, websockets, shellingham, pyreadline3, pyproject_hooks, pybase64, pyasn1, protobuf, overrides, oauthlib, mmh3, mdurl, importlib-resources, httptools, grpcio, cachetools, bcrypt, backoff, watchfiles, uvicorn, rsa, requests-oauthlib, pyasn1-modules, posthog, opentelemetry-proto, markdown-it-py, importlib-metadata, humanfriendly, googleapis-common-protos, build, rich, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, google-auth, coloredlogs, typer, opentelemetry-semantic-conventions, onnxruntime, kubernetes, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
      "\n",
      "    ---------------------------------------  1/45 [flatbuffers]\n",
      "   --- ------------------------------------  4/45 [websockets]\n",
      "   --- ------------------------------------  4/45 [websockets]\n",
      "   ---- -----------------------------------  5/45 [shellingham]\n",
      "   ----- ----------------------------------  6/45 [pyreadline3]\n",
      "   ------- --------------------------------  8/45 [pybase64]\n",
      "   -------- -------------------------------  9/45 [pyasn1]\n",
      "   -------- ------------------------------- 10/45 [protobuf]\n",
      "   -------- ------------------------------- 10/45 [protobuf]\n",
      "   -------- ------------------------------- 10/45 [protobuf]\n",
      "   ---------- ----------------------------- 12/45 [oauthlib]\n",
      "   ---------- ----------------------------- 12/45 [oauthlib]\n",
      "   ------------ --------------------------- 14/45 [mdurl]\n",
      "   ------------- -------------------------- 15/45 [importlib-resources]\n",
      "   --------------- ------------------------ 17/45 [grpcio]\n",
      "   --------------- ------------------------ 17/45 [grpcio]\n",
      "   --------------- ------------------------ 17/45 [grpcio]\n",
      "   ------------------ --------------------- 21/45 [watchfiles]\n",
      "   ------------------- -------------------- 22/45 [uvicorn]\n",
      "   -------------------- ------------------- 23/45 [rsa]\n",
      "   --------------------- ------------------ 24/45 [requests-oauthlib]\n",
      "   ---------------------- ----------------- 25/45 [pyasn1-modules]\n",
      "   ---------------------- ----------------- 25/45 [pyasn1-modules]\n",
      "   ---------------------- ----------------- 25/45 [pyasn1-modules]\n",
      "   ---------------------- ----------------- 25/45 [pyasn1-modules]\n",
      "   ----------------------- ---------------- 26/45 [posthog]\n",
      "   ----------------------- ---------------- 26/45 [posthog]\n",
      "   ------------------------ --------------- 27/45 [opentelemetry-proto]\n",
      "   ------------------------ --------------- 28/45 [markdown-it-py]\n",
      "   ------------------------ --------------- 28/45 [markdown-it-py]\n",
      "   ------------------------- -------------- 29/45 [importlib-metadata]\n",
      "   -------------------------- ------------- 30/45 [humanfriendly]\n",
      "   --------------------------- ------------ 31/45 [googleapis-common-protos]\n",
      "   --------------------------- ------------ 31/45 [googleapis-common-protos]\n",
      "   ---------------------------- ----------- 32/45 [build]\n",
      "   ----------------------------- ---------- 33/45 [rich]\n",
      "   ----------------------------- ---------- 33/45 [rich]\n",
      "   ----------------------------- ---------- 33/45 [rich]\n",
      "   ------------------------------- -------- 35/45 [opentelemetry-api]\n",
      "   -------------------------------- ------- 36/45 [google-auth]\n",
      "   -------------------------------- ------- 36/45 [google-auth]\n",
      "   -------------------------------- ------- 36/45 [google-auth]\n",
      "   --------------------------------- ------ 38/45 [typer]\n",
      "   ---------------------------- ---- 39/45 [opentelemetry-semantic-conventions]\n",
      "   ---------------------------- ---- 39/45 [opentelemetry-semantic-conventions]\n",
      "   ---------------------------- ---- 39/45 [opentelemetry-semantic-conventions]\n",
      "   ---------------------------- ---- 39/45 [opentelemetry-semantic-conventions]\n",
      "   ----------------------------------- ---- 40/45 [onnxruntime]\n",
      "   ----------------------------------- ---- 40/45 [onnxruntime]\n",
      "   ----------------------------------- ---- 40/45 [onnxruntime]\n",
      "   ----------------------------------- ---- 40/45 [onnxruntime]\n",
      "   ----------------------------------- ---- 40/45 [onnxruntime]\n",
      "   ----------------------------------- ---- 40/45 [onnxruntime]\n",
      "   ----------------------------------- ---- 40/45 [onnxruntime]\n",
      "   ----------------------------------- ---- 40/45 [onnxruntime]\n",
      "   ----------------------------------- ---- 40/45 [onnxruntime]\n",
      "   ----------------------------------- ---- 40/45 [onnxruntime]\n",
      "   ----------------------------------- ---- 40/45 [onnxruntime]\n",
      "   ----------------------------------- ---- 40/45 [onnxruntime]\n",
      "   ----------------------------------- ---- 40/45 [onnxruntime]\n",
      "   ----------------------------------- ---- 40/45 [onnxruntime]\n",
      "   ------------------------------------ --- 41/45 [kubernetes]\n",
      "   ------------------------------------ --- 41/45 [kubernetes]\n",
      "   ------------------------------------ --- 41/45 [kubernetes]\n",
      "   ------------------------------------ --- 41/45 [kubernetes]\n",
      "   ------------------------------------ --- 41/45 [kubernetes]\n",
      "   ------------------------------------ --- 41/45 [kubernetes]\n",
      "   ------------------------------------ --- 41/45 [kubernetes]\n",
      "   ------------------------------------ --- 41/45 [kubernetes]\n",
      "   ------------------------------------ --- 41/45 [kubernetes]\n",
      "   ------------------------------------ --- 41/45 [kubernetes]\n",
      "   ------------------------------------ --- 41/45 [kubernetes]\n",
      "   ------------------------------------ --- 41/45 [kubernetes]\n",
      "   ------------------------------------ --- 41/45 [kubernetes]\n",
      "   ------------------------------------ --- 41/45 [kubernetes]\n",
      "   ------------------------------------ --- 41/45 [kubernetes]\n",
      "   ------------------------------------ --- 41/45 [kubernetes]\n",
      "   ------------------------------------ --- 41/45 [kubernetes]\n",
      "   ------------------------------------ --- 41/45 [kubernetes]\n",
      "   ------------------------------------ --- 41/45 [kubernetes]\n",
      "   ------------------------------------ --- 41/45 [kubernetes]\n",
      "   ------------------------------------ --- 41/45 [kubernetes]\n",
      "   ------------------------------------ --- 41/45 [kubernetes]\n",
      "   ------------------------------------ --- 41/45 [kubernetes]\n",
      "   ------------------------------------ --- 41/45 [kubernetes]\n",
      "   ------------------------------------ --- 41/45 [kubernetes]\n",
      "   ------------------------------------ --- 41/45 [kubernetes]\n",
      "   ------------------------------------ --- 41/45 [kubernetes]\n",
      "   ------------------------------------ --- 41/45 [kubernetes]\n",
      "   ------------------------------------ --- 41/45 [kubernetes]\n",
      "   ------------------------------------- -- 42/45 [opentelemetry-sdk]\n",
      "   ------------------------------------- -- 42/45 [opentelemetry-sdk]\n",
      "   ---------------------------------------  44/45 [chromadb]\n",
      "   ---------------------------------------  44/45 [chromadb]\n",
      "   ---------------------------------------  44/45 [chromadb]\n",
      "   ---------------------------------------  44/45 [chromadb]\n",
      "   ---------------------------------------  44/45 [chromadb]\n",
      "   ---------------------------------------  44/45 [chromadb]\n",
      "   ---------------------------------------  44/45 [chromadb]\n",
      "   ---------------------------------------  44/45 [chromadb]\n",
      "   ---------------------------------------  44/45 [chromadb]\n",
      "   ---------------------------------------  44/45 [chromadb]\n",
      "   ---------------------------------------- 45/45 [chromadb]\n",
      "\n",
      "Successfully installed backoff-2.2.1 bcrypt-4.3.0 build-1.3.0 cachetools-5.5.2 chromadb-1.1.0 coloredlogs-15.0.1 durationpy-0.10 flatbuffers-25.9.23 google-auth-2.40.3 googleapis-common-protos-1.70.0 grpcio-1.75.0 httptools-0.6.4 humanfriendly-10.0 importlib-metadata-8.7.0 importlib-resources-6.5.2 kubernetes-33.1.0 markdown-it-py-4.0.0 mdurl-0.1.2 mmh3-5.2.0 oauthlib-3.3.1 onnxruntime-1.22.1 opentelemetry-api-1.37.0 opentelemetry-exporter-otlp-proto-common-1.37.0 opentelemetry-exporter-otlp-proto-grpc-1.37.0 opentelemetry-proto-1.37.0 opentelemetry-sdk-1.37.0 opentelemetry-semantic-conventions-0.58b0 overrides-7.7.0 posthog-5.4.0 protobuf-6.32.1 pyasn1-0.6.1 pyasn1-modules-0.4.2 pybase64-1.4.2 pypika-0.48.9 pyproject_hooks-1.2.0 pyreadline3-3.5.4 requests-oauthlib-2.0.0 rich-14.1.0 rsa-4.9.1 shellingham-1.5.4 typer-0.19.2 uvicorn-0.37.0 watchfiles-1.1.0 websockets-15.0.1 zipp-3.23.0\n"
     ]
    }
   ],
   "source": [
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f574cc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "client = chromadb.PersistentClient(path='./chromadb_tag_only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f4e5a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df20400a",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = client.get_or_create_collection(name='tour_tag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "901741df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brain\\AppData\\Local\\Temp\\ipykernel_24604\\1253391701.py:4: DtypeWarning: Columns (2,55,57,58,59,60,63,64,67,68,69,70,72) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('C:\\\\Users\\\\brain\\\\Desktop\\\\3차 프로젝트\\\\GIT\\\\crawling-data\\\\합친 데이터셋\\\\찐찐찐찐막 전국 데이터.csv')\n"
     ]
    }
   ],
   "source": [
    "# pd 생성 후 태그만 임베딩하기\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('C:\\\\Users\\\\brain\\\\Desktop\\\\3차 프로젝트\\\\GIT\\\\crawling-data\\\\합친 데이터셋\\\\찐찐찐찐막 전국 데이터.csv')\n",
    "\n",
    "documents = [df.iloc[idx]['태그'] for idx in range(len(df))]\n",
    "embedded_docs = embedding_model.encode(documents).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1322b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메타 데이터 생성\n",
    "import re\n",
    "\n",
    "metadata=[]\n",
    "for idx in range(len(df)):\n",
    "    meta_data = {}\n",
    "    row = df.iloc[idx][df.iloc[idx].notna()]\n",
    "    cols = list(row.index)   # None이 아닌 컬럼들 == row.index \n",
    "\n",
    "    for col in cols:\n",
    "      if col == '태그':\n",
    "        meta_data['text'] = row[col]\n",
    "      elif col == '주소':\n",
    "        meta_data['region'] = row[col].split()[0]\n",
    "      elif col == 'place':\n",
    "        meta_data['place'] = row[col]\n",
    "    metadata.append(meta_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b330adb3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metadata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmetadata\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'metadata' is not defined"
     ]
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb09532",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19854/19854 [00:00<00:00, 2331225.65it/s]\n"
     ]
    }
   ],
   "source": [
    "# 컬렉션에 추가\n",
    "from tqdm import tqdm\n",
    "collection.add(\n",
    "    ids = [str(i) for i in tqdm(range(len(documents)))],\n",
    "    embeddings = [embedded_docs],\n",
    "    documents = documents,      # 오류나면 빼기\n",
    "    metadatas = metadata\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2b47585",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedding_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 질문 입력 -> 질문 임베딩 -> collection에 전달 -> 상위 결과 5개 뽑기\u001b[39;00m\n\u001b[32m      2\u001b[39m question = \u001b[33m'\u001b[39m\u001b[33m가족들과 가기 좋은 캠핑장 알려줘\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m embedded_question = \u001b[43membedding_model\u001b[49m.encode(question).tolist()\n\u001b[32m      6\u001b[39m top_n = \u001b[32m5\u001b[39m\n\u001b[32m      7\u001b[39m context = collection.query(\n\u001b[32m      8\u001b[39m     query_embeddings= embedded_question,\n\u001b[32m      9\u001b[39m     n_results = top_n\n\u001b[32m     10\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'embedding_model' is not defined"
     ]
    }
   ],
   "source": [
    "# 질문 입력 -> 질문 임베딩 -> collection에 전달 -> 상위 결과 5개 뽑기\n",
    "question = '가족들과 가기 좋은 캠핑장 알려줘'\n",
    "\n",
    "embedded_question = embedding_model.encode(question).tolist()\n",
    "\n",
    "top_n = 5\n",
    "context = collection.query(\n",
    "    query_embeddings= embedded_question,\n",
    "    n_results = top_n\n",
    ")\n",
    "\n",
    "# 확인용 코드\n",
    "print(f'Q: {question}')\n",
    "for i in range(top_n):\n",
    "    print(context)\n",
    "    print(f\"장소 이름 : {context['metadatas'][i][0]['place']}\")\n",
    "    print(f\"주소 : {context['metadatas'][i][0]['주소']}\")\n",
    "    print(f\"태그 : {context['metadatas'][i][0]['태그']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d0f4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sllm 모델 생성\n",
    "from transformers import AutoModel\n",
    "\n",
    "model_name = \"0lipa/SEED-1.5B-travel-finetuned\"\n",
    "# sllm = AutoModel.from_pretrained(\"0lipa/SEED-1.5B-travel-finetuned\", torch_dtype=\"auto\")\n",
    "sllm = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d2f4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트 생성 -> sllm 응답 요청 \n",
    "\n",
    "# 채팅 로그 수정할 수 있는 함수 설정\n",
    "def modify_chat_log(chatting_log,message):\n",
    "    if len(chatting_log)% 2 == 0:\n",
    "        chatting_log.append({\"role\": \"assistant\", \"content\": message})\n",
    "    else:\n",
    "        chatting_log.append({'role':'user','content':message})\n",
    "    return chatting_log\n",
    "\n",
    "prompt = f'{question} \\n 다음 정보를 활용하여 간략하게 10문장 이내로 출력하시오.{context}'\n",
    "\n",
    "chat_history = [\n",
    "    {\"role\": \"system\", \"content\": \"너는 대한민국 관광지를 친절하게 알려주는 챗봇이야. 질문에 친절하게 간략하게 답변해줘. 단, 문맥에 없는 정보는 만들어내지마.\"}\n",
    "]\n",
    "\n",
    "chat_history = modify_chat_log(chat_history,prompt)\n",
    "\n",
    "inputs = tokenizer.apply_chat_template(chat_history, add_generation_prompt=True, return_dict=True, return_tensors=\"pt\")\n",
    "inputs = inputs.to(\"cuda\")\n",
    "output_ids = sllm.generate(\n",
    "    **inputs,\n",
    "    max_length=1024,\n",
    "    stop_strings=[\"<|endofturn|>\", \"<|stop|>\"],\n",
    "    tokenizer=tokenizer\n",
    "    )\n",
    "print(tokenizer.batch_decode(output_ids)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c368327b",
   "metadata": {},
   "source": [
    "---\n",
    "### Chromadb\n",
    "- embedding model : 'all-MiniLM-L6-v2'\n",
    "- Document(page_content = 태그와 짧은 설명 , metadata = 나머지 정보들)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d621472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd 생성 후 태그랑 short_info 합쳐서 임베딩하기\n",
    "\n",
    "df = pd.read_csv('찐막 전국 데이터.csv')\n",
    "\n",
    "documents = []\n",
    "for idx in range(len(df)):\n",
    "    data = ''\n",
    "    if df.iloc[idx]['태그'] is not None and df.iloc[idx]['short_info'] is not None:\n",
    "        data = df.iloc[idx]['태그'] + \" \" + df.iloc[idx]['short_info']\n",
    "    elif df.iloc[idx]['태그'] is not None and df.iloc[idx]['short_info'] is None:\n",
    "        data = df.iloc[idx]['태그']\n",
    "    elif df.iloc[idx]['태그'] is None and df.iloc[idx]['short_info'] is not None:\n",
    "        data = df.iloc[idx]['short_info']\n",
    "    else:\n",
    "        pass\n",
    "    documents.append(data)\n",
    "\n",
    "embedded_docs = embedding_model.encode(documents).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5bafbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메타 데이터 생성\n",
    "\n",
    "def remove_nonwords(text):\n",
    "    if type(text)!= float :\n",
    "        text = text.replace(':)',\"\")    # :) 제거\n",
    "        text = text.replace(\"※\",\"\")\n",
    "        text = text.replace('-','')\n",
    "        text = text.replace('\\n더보기','')      # \\n 더보기, \\n 닫기, \\n 제거\n",
    "        text = text.replace('\\n닫기','')\n",
    "        text = text.replace('\\r\\n',' ')\n",
    "        text = text.replace('\\n',' ')\n",
    "        text = text.replace('\\r', ' ')\n",
    "        text = re.sub('[^a-zA-Z가-힣\\'\"· 0-9.,()㎡[0-9]~[0-9]]','',text) # 숫자와 숫자 사이에 있는 ~ 남겨야함\n",
    "    else:\n",
    "        pass\n",
    "    return text     # 제거한 텍스트 반환\n",
    "\n",
    "metadata=[]\n",
    "for idx in range(len(df)):\n",
    "    meta_data = {}\n",
    "    row = df.iloc[idx][df.iloc[idx].notna()]\n",
    "    cols = list(row.index)   # None이 아닌 컬럼들 == row.index \n",
    "\n",
    "    for col in cols:     \n",
    "        modified_data = remove_nonwords(row[col])\n",
    "        meta_data[col] = modified_data\n",
    "    metadata.append(meta_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146b25e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬렉션에 추가\n",
    "collection.add(\n",
    "    ids = [str(i) for i in range(len(documents))],\n",
    "    embeddings = [embedded_docs],\n",
    "    documents = documents,      # 오류나면 빼기\n",
    "    metadatas = metadata\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a034df21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문 입력 -> 질문 임베딩 -> collection에 전달 -> 상위 결과 5개 뽑기\n",
    "question = '가족들과 가기 좋은 캠핑장 알려줘'\n",
    "\n",
    "embedded_question = embedding_model.encode(question).tolist()\n",
    "\n",
    "top_n = 5\n",
    "context = collection.query(\n",
    "    query_embeddings= embedded_question,\n",
    "    n_results = top_n\n",
    ")\n",
    "\n",
    "# 확인용 코드\n",
    "print(f'Q: {question}')\n",
    "for i in range(top_n):\n",
    "    print(context)\n",
    "    print(f\"장소 이름 : {context['metadatas'][i][0]['place']}\")\n",
    "    print(f\"주소 : {context['metadatas'][i][0]['주소']}\")\n",
    "    print(f\"태그 : {context['metadatas'][i][0]['태그']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9f44c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sllm 모델 생성\n",
    "from transformers import AutoModel\n",
    "\n",
    "model_name = \"0lipa/SEED-1.5B-travel-finetuned\"\n",
    "# sllm = AutoModel.from_pretrained(\"0lipa/SEED-1.5B-travel-finetuned\", torch_dtype=\"auto\")\n",
    "sllm = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9241a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트 생성 -> sllm 응답 요청 \n",
    "\n",
    "# 채팅 로그 수정할 수 있는 함수 설정\n",
    "def modify_chat_log(chatting_log,message):\n",
    "    if len(chatting_log)% 2 == 0:\n",
    "        chatting_log.append({\"role\": \"assistant\", \"content\": message})\n",
    "    else:\n",
    "        chatting_log.append({'role':'user','content':message})\n",
    "    return chatting_log\n",
    "\n",
    "prompt = f'{question} \\n 다음 정보를 활용하여 간략하게 10문장 이내로 출력하시오.{context}'\n",
    "\n",
    "chat_history = [\n",
    "    {\"role\": \"system\", \"content\": \"너는 대한민국 관광지를 친절하게 알려주는 챗봇이야. 질문에 친절하게 간략하게 답변해줘. 단, 문맥에 없는 정보는 만들어내지마.\"}\n",
    "]\n",
    "\n",
    "chat_history = modify_chat_log(chat_history,prompt)\n",
    "\n",
    "inputs = tokenizer.apply_chat_template(chat_history, add_generation_prompt=True, return_dict=True, return_tensors=\"pt\")\n",
    "inputs = inputs.to(\"cuda\")\n",
    "output_ids = sllm.generate(\n",
    "    **inputs,\n",
    "    max_length=1024,\n",
    "    stop_strings=[\"<|endofturn|>\", \"<|stop|>\"],\n",
    "    tokenizer=tokenizer\n",
    "    )\n",
    "print(tokenizer.batch_decode(output_ids)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f57316",
   "metadata": {},
   "source": [
    "----\n",
    "# Retriever 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31cb307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document로 저장\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter      # 재귀적으로 text splitter  큰 chunk -> 작은 chunk 로 분할할 chunk size 지정\n",
    "import preprocess_functions as pf\n",
    "\n",
    "documents = pf.make_tag_page_content('찐막 전국 데이터.csv')    # 태그와 짤막한 설명을 같이 page_content에 넣어주는 경우\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f51ee80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 모델 생성 및 vectorstore 생성\n",
    "from langchain_chroma.vectorstores import Chroma\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "vector_store = Chroma.from_documents(documents, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cb6c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Retriever를 활용한 검색\n",
    "\n",
    "question = '가족들과 가기 좋은 캠핑장 알려줘'\n",
    "\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type='similarity',\n",
    "    search_kwargs = {'k':10}\n",
    ")\n",
    "\n",
    "retriever_result = retriever.batch([question])\n",
    "retriever_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fedca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트 템플릿 생성\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chatting_log = [\n",
    "    ('system', '너는 대한민국 관광지를 친절하게 알려주는 챗봇이야. 질문에 친절하게 간략하게 답변해줘. 단, 문맥에 없는 정보는 만들어내지마.'),\n",
    "    ('user', '''어린이의 질문에 context만을 이용해 답변하세요.\n",
    "context에서 확인할 수 없는 질문이라면 모른다고 답변해야 합니다.\n",
    "최종 응답에는 참조한 context에 대한 정보를 추가해 주세요.\n",
    "\n",
    "     질문: {query}\n",
    "     context: {context}\n",
    "''')\n",
    "]\n",
    "\n",
    "prompt_tpl = ChatPromptTemplate(chatting_log)\n",
    "# prompt_tpl.invoke({'query': query, 'context': retriever_result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34350d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sllm 모델 생성\n",
    "from transformers import AutoModel\n",
    "from transformers.models import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"0lipa/SEED-1.5B-travel-finetuned\"\n",
    "# sllm = AutoModel.from_pretrained(\"0lipa/SEED-1.5B-travel-finetuned\", torch_dtype=\"auto\")\n",
    "sllm = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf84fee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체인 생성\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = prompt_tpl | sllm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab75586",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_result = retriever.batch([query])\n",
    "response = chain.invoke({'query': question, 'context': retriever_result})\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
